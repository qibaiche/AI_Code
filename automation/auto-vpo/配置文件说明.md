# 配置文件说明

## 新的配置文件结构

### 主要配置文件

1. **`spark_automation_config.yaml`** ⭐ 新文件（推荐使用）
   - 格式：YAML
   - 用途：Spark自动化的关键参数
   - 包含内容：
     - Mole可执行文件路径
     - Spark网址
     - VPO类别（correlation/engineering/walk the lot）
     - Test Program路径
   
   **优点**：
   - ✅ 结构化格式，易于程序读取
   - ✅ 支持注释，便于理解
   - ✅ 可扩展性强
   - ✅ 避免路径转义问题

2. **`workflow_automation/config.yaml`**
   - 格式：YAML
   - 用途：工作流的详细配置
   - 包含内容：
     - 路径配置（输入、输出、日志）
     - Mole详细配置
     - Spark详细配置
     - GTS配置
     - 超时和重试配置

### 已弃用的文件

- **`file path.txt`** ❌ 已弃用
  - 旧的纯文本配置文件
  - 已被`spark_automation_config.yaml`替代
  - 可以安全删除

---

## 配置优先级

当同一个参数在多个配置文件中存在时：

1. **`spark_automation_config.yaml`** 优先级最高
2. **`workflow_automation/config.yaml`** 作为默认值

例如：
- 如果`spark_automation_config.yaml`中定义了`vpo_category: "engineering"`
- 而`config.yaml`中是`vpo_category: "correlation"`
- 最终使用的是`"engineering"`

---

## 如何修改配置

### 修改Spark相关参数（推荐）

编辑 **`spark_automation_config.yaml`**：

```yaml
spark:
  url: "https://spark.app.intel.com/dashboard"
  vpo_category: "correlation"  # 改为 engineering 或 walk the lot

test_program:
  tp_path: "\\\\your\\network\\path\\here"
```

### 修改高级参数

编辑 **`workflow_automation/config.yaml`**：

```yaml
spark:
  timeout: 60  # 超时时间
  retry_count: 3  # 重试次数
  headless: false  # 是否无头模式
```

---

## 快速开始

1. ✅ 检查`spark_automation_config.yaml`中的参数是否正确
2. ✅ 运行测试：`测试Spark.bat`
3. ✅ 如果需要修改，编辑`spark_automation_config.yaml`
4. ❌ 删除旧文件`file path.txt`（可选）

---

## 常见问题

**Q: 我可以删除`file path.txt`吗？**
A: 可以！所有配置已迁移到`spark_automation_config.yaml`

**Q: 修改配置后需要重启程序吗？**
A: 是的，修改配置文件后需要重新运行脚本才能生效

**Q: VPO类别支持哪些值？**
A: 
- `correlation` - Correlation实验
- `engineering` - Engineering实验
- `walk the lot` - Walk the lot实验

**Q: TP路径中的反斜杠要怎么写？**
A: 在YAML中，使用双反斜杠`\\\\`，或者使用正斜杠`/`也可以

---

## 文件位置

```
Auto VPO/
├── spark_automation_config.yaml  ← 新的配置文件（这个！）
├── file path.txt                  ← 旧文件，可删除
├── Source Lot.csv
├── MIR Comments.txt
├── 测试Spark.bat
├── 测试Mole.bat
└── workflow_automation/
    └── config.yaml                ← 详细配置
```

