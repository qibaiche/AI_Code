"""è°ƒè¯•è„šæœ¬ï¼šåªæ‰§è¡Œâ€œç­‰å¾…30åˆ†é’Ÿåä» Spark Dashboard æ”¶é›† VPO å¹¶å†™å› CSVâ€çš„æ­¥éª¤ã€‚

ç”¨æ³•ï¼ˆåœ¨ automation/auto-vpo ç›®å½•ä¸‹æ‰§è¡Œï¼‰ï¼š

    python spark\\debug_collect_vpo.py

é€»è¾‘ï¼š
1. åœ¨ output ç›®å½•ä¸­æ‰¾åˆ°æœ€æ–°çš„ MIR_Results_*.csv
2. è¯»å–è¡Œæ•° Nï¼Œä½œä¸ºæœŸæœ› VPO æ•°é‡
3. è°ƒç”¨ SparkSubmitter.collect_recent_vpos_from_dashboard(N)
4. å°†æ”¶é›†åˆ°çš„ VPO åå‘åŒ¹é…å› CSVï¼Œæ¯è¡Œæ–°å¢ä¸€åˆ— VPO
5. ç”Ÿæˆ MIR_Results_with_VPO_DEBUG_*.csv

æ³¨æ„ï¼š
- ç­‰å¾…æ—¶é—´ç”± config.yaml ä¸­ spark.vpo_collect_wait_minutes æ§åˆ¶ï¼Œé»˜è®¤ 0 åˆ†é’Ÿï¼ˆ0 è¡¨ç¤ºä¸ç­‰å¾…ï¼‰ã€‚
"""

import sys
from datetime import datetime
from pathlib import Path

import pandas as pd

# å°† auto-vpo æ ¹ç›®å½•åŠ å…¥ sys.pathï¼Œæ–¹ä¾¿å¯¼å…¥ workflow_automation æ¨¡å—
current_dir = Path(__file__).parent          # .../automation/auto-vpo/spark
parent_dir = current_dir.parent              # .../automation/auto-vpo
sys.path.insert(0, str(parent_dir))

from workflow_automation.config_loader import load_config  # noqa: E402
from workflow_automation.spark_submitter import SparkSubmitter  # noqa: E402


def main(no_wait: bool = False) -> None:
    print("=" * 80)
    print("ğŸ§ª Spark VPO æ”¶é›†è°ƒè¯•è„šæœ¬")
    print("=" * 80)
    print()

    # åŠ è½½é…ç½®
    config_path = parent_dir / "workflow_automation" / "config.yaml"
    if not config_path.exists():
        print("âŒ é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        print(f"   é¢„æœŸä½ç½®ï¼š{config_path}")
        input("\næŒ‰ Enter é”®é€€å‡º...")
        return

    config = load_config(config_path)

    # æŸ¥æ‰¾æœ€æ–° MIR_Results_*.csvï¼ˆæ”¯æŒæ–°çš„ç›®å½•ç»“æ„ï¼‰
    output_dir = config.paths.output_dir
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼š{output_dir}")

    if not output_dir.exists():
        print("âŒ é”™è¯¯ï¼šoutput ç›®å½•ä¸å­˜åœ¨ï¼")
        input("\næŒ‰ Enter é”®é€€å‡º...")
        return

    mir_files = []
    
    # æ–°ç»“æ„ï¼šç›´æ¥åœ¨ 01_MIR/ ç›®å½•ä¸­æŸ¥æ‰¾
    mir_results_dir = output_dir / "01_MIR"
    if mir_results_dir.exists():
        found_files = list(mir_results_dir.glob("MIR_Results_*.csv"))
        found_files.extend(mir_results_dir.glob("MIR_Results_*.xlsx"))
        if found_files:
            mir_files.extend(found_files)
            print(f"   ğŸ“ åœ¨ 01_MIR ç›®å½•ä¸­æ‰¾åˆ°æ–‡ä»¶")
    
    # å‘åå…¼å®¹ï¼šæŸ¥æ‰¾æ—§çš„å·¥ä½œç›®å½•ç»“æ„ï¼ˆrun_YYYYMMDD_HHMMSS/01_MIR/ï¼‰
    if not mir_files:
        work_dirs = sorted(output_dir.glob("run_*"), reverse=True)
        for work_dir in work_dirs:
            # æ–°ç»“æ„ï¼š01_MIR ç›®å½•
            mir_results_dir = work_dir / "01_MIR"
            if not mir_results_dir.exists():
                # å‘åå…¼å®¹ï¼š01_MIR_Results ç›®å½•
                mir_results_dir = work_dir / "01_MIR_Results"
            
            if mir_results_dir.exists():
                found_files = list(mir_results_dir.glob("MIR_Results_*.csv"))
                found_files.extend(mir_results_dir.glob("MIR_Results_*.xlsx"))
                if found_files:
                    mir_files.extend(found_files)
                    print(f"   ğŸ“ åœ¨å·¥ä½œç›®å½•ä¸­æ‰¾åˆ°æ–‡ä»¶: {work_dir.name}")
                    break
    
    # å‘åå…¼å®¹ï¼šåœ¨outputæ ¹ç›®å½•æŸ¥æ‰¾ï¼ˆæ—§æ ¼å¼ï¼‰
    if not mir_files:
        mir_files = sorted(output_dir.glob("MIR_Results_*.csv"), reverse=True)
        mir_files.extend(sorted(output_dir.glob("MIR_Results_*.xlsx"), reverse=True))
        if mir_files:
            print(f"   ğŸ“ åœ¨outputæ ¹ç›®å½•ä¸­æ‰¾åˆ°æ–‡ä»¶ï¼ˆæ—§æ ¼å¼ï¼‰")
    
    if not mir_files:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° MIR_Results_*.csv æˆ– *.xlsx æ–‡ä»¶ï¼")
        work_dirs = list(output_dir.glob("run_*"))
        if work_dirs:
            print(f"   æ‰¾åˆ° {len(work_dirs)} ä¸ªå·¥ä½œç›®å½•ï¼Œä½†æœªæ‰¾åˆ°MIRç»“æœæ–‡ä»¶")
        print("   æ–‡ä»¶åº”ä½äºï¼šoutput/01_MIR/ æˆ– output/run_*/01_MIR/ æˆ– output/")
        input("\næŒ‰ Enter é”®é€€å‡º...")
        return

    # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼‰
    selected_file = max(mir_files, key=lambda p: p.stat().st_mtime)
    print(f"âœ… ä½¿ç”¨æœ€æ–° MIR æ–‡ä»¶ï¼š{selected_file.name}")

    # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©æ­£ç¡®çš„è¯»å–æ–¹æ³•
    if selected_file.suffix.lower() == '.xlsx':
        try:
            df = pd.read_excel(selected_file, engine='openpyxl')
        except ImportError:
            print("âŒ é”™è¯¯ï¼šéœ€è¦å®‰è£… openpyxl æ¥è¯»å– Excel æ–‡ä»¶ï¼")
            print("   è¯·è¿è¡Œ: pip install openpyxl")
            input("\næŒ‰ Enter é”®é€€å‡º...")
            return
    else:
        df = pd.read_csv(selected_file, encoding='utf-8-sig')
    if df.empty:
        print("âŒ é”™è¯¯ï¼šMIR ç»“æœæ–‡ä»¶ä¸ºç©ºï¼")
        input("\næŒ‰ Enter é”®é€€å‡º...")
        return

    expected_count = len(df)
    print(f"ğŸ”¢ MIR è¡Œæ•°ï¼š{expected_count}")
    print()

    # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦è·³è¿‡ç­‰å¾…
    if no_wait:
        wait_minutes = 0
        print("â±  è°ƒè¯•æ¨¡å¼ï¼šä¸ç­‰å¾…ï¼Œç«‹å³ä» Spark Dashboard æ”¶é›† VPO ...")
    else:
        wait_minutes = getattr(config.spark, "vpo_collect_wait_minutes", 0)
        print(f"â±  å°†åœ¨ {wait_minutes} åˆ†é’Ÿåä» Spark Dashboard æ”¶é›† VPOï¼ˆ0 è¡¨ç¤ºä¸ç­‰å¾…ï¼‰...")
        print("    ï¼ˆå¦‚éœ€ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œå¯ä»¥åœ¨ config.yaml ä¸­è®¾ç½® vpo_collect_wait_minutesï¼‰")
    print()

    submitter = SparkSubmitter(config.spark)

    try:
        # å°†ç­‰å¾…æ—¶é—´é€šè¿‡ config ä¼ é€’ç»™ submitterï¼ˆcollect_recent_vpos_from_dashboard å†…éƒ¨ä½¿ç”¨ï¼‰
        submitter.config.vpo_collect_wait_minutes = wait_minutes
        vpo_list = submitter.collect_recent_vpos_from_dashboard(expected_count=expected_count)
    finally:
        # ç¡®ä¿æµè§ˆå™¨å…³é—­
        submitter._close_driver()

    if not vpo_list:
        print("âš ï¸ æœªæ”¶é›†åˆ°ä»»ä½• VPOï¼Œç»“æŸã€‚")
        input("\næŒ‰ Enter é”®é€€å‡º...")
        return

    print(f"âœ… æ”¶é›†åˆ° {len(vpo_list)} ä¸ª VPOï¼š{vpo_list}")

    # åå‘åŒ¹é…å›åŸ CSV
    vpo_list_reversed = list(reversed(vpo_list))
    mir_with_vpo = df.copy()
    vpo_col_name = "VPO"

    if vpo_col_name in mir_with_vpo.columns:
        print(f"âš ï¸ è­¦å‘Šï¼šåŸæ–‡ä»¶ä¸­å·²å­˜åœ¨åˆ— '{vpo_col_name}'ï¼Œå°†è¦†ç›–è¯¥åˆ—çš„å€¼ã€‚")

    mir_with_vpo[vpo_col_name] = ""

    max_count = min(len(mir_with_vpo), len(vpo_list_reversed))
    for i in range(max_count):
        mir_with_vpo.at[mir_with_vpo.index[i], vpo_col_name] = vpo_list_reversed[i]

    # ä¿å­˜åˆ° 01_MIR ç›®å½•
    mir_dir = output_dir / "01_MIR"
    mir_dir.mkdir(parents=True, exist_ok=True)
    
    date_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = mir_dir / f"MIR_Results_with_VPO_DEBUG_{date_str}.csv"
    mir_with_vpo.to_csv(output_file, index=False, encoding="utf-8-sig")

    print()
    print("âœ… å·²ç”Ÿæˆå¸¦ VPO çš„è°ƒè¯•æ–‡ä»¶ï¼š")
    print(f"   {output_file}")
    print(f"   å…±å†™å…¥ {max_count} æ¡ VPO è®°å½•ï¼ˆæ€»è¡Œæ•°ï¼š{len(mir_with_vpo)}ï¼‰")
    print()
    
    # å°† VPO å¡«å†™åˆ° SPARK æ–‡ä»¶å¤¹é‡Œæœ€æ–°çš„æ–‡ä»¶ä¸­
    print("=" * 80)
    print("ğŸ“ æ­£åœ¨å°† VPO å¡«å†™åˆ° SPARK æ–‡ä»¶å¤¹...")
    print("=" * 80)
    
    spark_files = []
    
    # æŸ¥æ‰¾ SPARK æ–‡ä»¶å¤¹ï¼ˆæ”¯æŒæ–°æ—§ä¸¤ç§ç»“æ„ï¼‰
    # æ–°ç»“æ„ï¼šoutput/run_*/Spark/
    work_dirs = sorted(output_dir.glob("run_*"), reverse=True)
    for work_dir in work_dirs:
        spark_dir = work_dir / "Spark"
        if spark_dir.exists():
            found_files = list(spark_dir.glob("MIR_Results_For_Spark_*.xlsx"))
            found_files.extend(list(spark_dir.glob("MIR_Results_For_Spark_*.csv")))
            if found_files:
                spark_files.extend(found_files)
                print(f"   ğŸ“ åœ¨å·¥ä½œç›®å½•ä¸­æ‰¾åˆ° SPARK æ–‡ä»¶: {work_dir.name}")
                break
    
    # å‘åå…¼å®¹ï¼šæ—§ç»“æ„ output/02_SPARK/
    if not spark_files:
        spark_dir = output_dir / "02_SPARK"
        if spark_dir.exists():
            found_files = list(spark_dir.glob("MIR_Results_For_Spark_*.xlsx"))
            found_files.extend(list(spark_dir.glob("MIR_Results_For_Spark_*.csv")))
            if found_files:
                spark_files.extend(found_files)
                print(f"   ğŸ“ åœ¨ 02_SPARK ç›®å½•ä¸­æ‰¾åˆ°æ–‡ä»¶")
    
    if not spark_files:
        print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ° SPARK æ–‡ä»¶å¤¹ä¸­çš„ MIR_Results_For_Spark_*.xlsx æ–‡ä»¶")
        print("   è·³è¿‡å¡«å†™ VPO åˆ° SPARK æ–‡ä»¶")
    else:
        # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼‰
        selected_spark_file = max(spark_files, key=lambda p: p.stat().st_mtime)
        print(f"âœ… ä½¿ç”¨æœ€æ–° SPARK æ–‡ä»¶ï¼š{selected_spark_file.name}")
        
        try:
            # è¯»å– SPARK æ–‡ä»¶
            if selected_spark_file.suffix.lower() == '.xlsx':
                try:
                    spark_df = pd.read_excel(selected_spark_file, engine='openpyxl')
                except ImportError:
                    print("âŒ é”™è¯¯ï¼šéœ€è¦å®‰è£… openpyxl æ¥è¯»å– Excel æ–‡ä»¶ï¼")
                    print("   è¯·è¿è¡Œ: pip install openpyxl")
                else:
                    # å¡«å†™ VPO åˆ° SPARK æ–‡ä»¶
                    vpo_col_name = "VPO"
                    
                    if vpo_col_name in spark_df.columns:
                        print(f"âš ï¸ è­¦å‘Šï¼šSPARK æ–‡ä»¶ä¸­å·²å­˜åœ¨åˆ— '{vpo_col_name}'ï¼Œå°†è¦†ç›–è¯¥åˆ—çš„å€¼ã€‚")
                    
                    spark_df[vpo_col_name] = ""
                    
                    # ä½¿ç”¨åå‘åŒ¹é…ï¼Œå’Œ MIR æ–‡ä»¶ä¸€æ ·çš„æ–¹å¼
                    spark_max_count = min(len(spark_df), len(vpo_list_reversed))
                    for i in range(spark_max_count):
                        spark_df.at[spark_df.index[i], vpo_col_name] = vpo_list_reversed[i]
                    
                    # ä¿å­˜æ–‡ä»¶ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
                    try:
                        spark_df.to_excel(selected_spark_file, index=False, engine='openpyxl')
                        print(f"âœ… å·²æ›´æ–° SPARK æ–‡ä»¶ï¼š{selected_spark_file.name}")
                        print(f"   å…±å†™å…¥ {spark_max_count} æ¡ VPO è®°å½•ï¼ˆæ€»è¡Œæ•°ï¼š{len(spark_df)}ï¼‰")
                    except Exception as e:
                        # å¦‚æœ Excel ä¿å­˜å¤±è´¥ï¼Œå°è¯•ä¿å­˜ä¸º CSV
                        print(f"âš ï¸ ä¿å­˜ Excel æ–‡ä»¶å¤±è´¥: {e}ï¼Œå°è¯•ä¿å­˜ä¸º CSV æ ¼å¼...")
                        csv_file = selected_spark_file.with_suffix('.csv')
                        spark_df.to_csv(csv_file, index=False, encoding="utf-8-sig")
                        print(f"âœ… å·²ä¿å­˜ä¸º CSV æ–‡ä»¶ï¼š{csv_file.name}")
            else:
                # CSV æ–‡ä»¶
                spark_df = pd.read_csv(selected_spark_file, encoding='utf-8-sig')
                
                # å¡«å†™ VPO åˆ° SPARK æ–‡ä»¶
                vpo_col_name = "VPO"
                
                if vpo_col_name in spark_df.columns:
                    print(f"âš ï¸ è­¦å‘Šï¼šSPARK æ–‡ä»¶ä¸­å·²å­˜åœ¨åˆ— '{vpo_col_name}'ï¼Œå°†è¦†ç›–è¯¥åˆ—çš„å€¼ã€‚")
                
                spark_df[vpo_col_name] = ""
                
                # ä½¿ç”¨åå‘åŒ¹é…ï¼Œå’Œ MIR æ–‡ä»¶ä¸€æ ·çš„æ–¹å¼
                spark_max_count = min(len(spark_df), len(vpo_list_reversed))
                for i in range(spark_max_count):
                    spark_df.at[spark_df.index[i], vpo_col_name] = vpo_list_reversed[i]
                
                # ä¿å­˜æ–‡ä»¶ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
                spark_df.to_csv(selected_spark_file, index=False, encoding="utf-8-sig")
                print(f"âœ… å·²æ›´æ–° SPARK æ–‡ä»¶ï¼š{selected_spark_file.name}")
                print(f"   å…±å†™å…¥ {spark_max_count} æ¡ VPO è®°å½•ï¼ˆæ€»è¡Œæ•°ï¼š{len(spark_df)}ï¼‰")
        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼šæ›´æ–° SPARK æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            import traceback
            print(traceback.format_exc())
    
    print()
    input("æŒ‰ Enter é”®é€€å‡º...")


if __name__ == "__main__":
    # å‘½ä»¤è¡Œå¯é€‰å‚æ•°ï¼š--no-wait  è¡¨ç¤ºä¸ç­‰å¾…ï¼Œç«‹å³æ”¶é›† VPO
    no_wait_flag = "--no-wait" in sys.argv
    main(no_wait=no_wait_flag)


